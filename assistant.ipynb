{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================start===========\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mic \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m     97\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# Chuyển âm thanh thành văn bản (hỗ trợ tiếng Việt)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m======================recording===========================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\app\\Python\\Lib\\site-packages\\speech_recognition\\__init__.py:709\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    711\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32md:\\app\\Python\\Lib\\site-packages\\speech_recognition\\__init__.py:211\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\app\\Python\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel,GPT2Tokenizer\n",
    "import torch\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import io\n",
    "import speech_recognition as sr\n",
    "import random \n",
    "import re\n",
    "import time\n",
    "def text2speech(text):\n",
    "    # Tạo âm thanh bằng gTTS\n",
    "    tts = gTTS(text, lang='vi')\n",
    "\n",
    "    # Tải âm thanh vào bộ nhớ (BytesIO)\n",
    "    mp3_fp = io.BytesIO()\n",
    "    tts.write_to_fp(mp3_fp)\n",
    "    mp3_fp.seek(0)\n",
    "\n",
    "    # Phát âm thanh với pygame\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(mp3_fp, 'mp3')\n",
    "    pygame.mixer.music.play()\n",
    "    # Chờ đến khi âm thanh phát xong\n",
    "    while pygame.mixer.music.get_busy():  # Check if music is still playing\n",
    "        pygame.time.Clock().tick(10)  # Wait for the music to finish\n",
    "def assistant(conversation:list):\n",
    "    if(len(conversation)>3):\n",
    "        conversation = conversation[-3:-1]\n",
    "    context = ''\n",
    "    for i in conversation:\n",
    "        if(i['type']=='user'):\n",
    "            context += f'<|im_start|>user<|im_sep|>{i[\"message\"]}?<|im_end|>'\n",
    "        else:\n",
    "            context += f'<|im_start|>assistant<|im_sep|>{i[\"message\"]}<|im_end|>'\n",
    "\n",
    "    li = ['Bạn',\"Tôi\",'Tôi nghĩ', 'Bạn nên','Có thể']\n",
    "    element = random.choice(li)\n",
    "    input_text = f'{context}<|im_start|>assistant<|im_sep|>'\n",
    "    # input_text = f'{context}<|im_start|>assistant<|im_sep|>{element}'\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    model.eval()\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        attention_mask = inputs['attention_mask'],\n",
    "        do_sample=True,\n",
    "        max_length=256,# chỉnh\n",
    "        min_length=10,\n",
    "        top_k=40,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    print('context',context)\n",
    "    # Giải mã kết quả\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    print('origin',generated_text)\n",
    "    generated_text = re.sub(r'\\s*<\\|im_start\\|>\\s*', '<|im_start|>', generated_text)\n",
    "    generated_text = re.sub(r'\\s*<\\|im_sep\\|>\\s*', '<|im_sep|>', generated_text)\n",
    "    generated_text = re.sub(r'\\s*<\\|im_end\\|>\\s*', '<|im_end|>', generated_text)\n",
    "    generated_text = generated_text.replace(f'{context}<|im_start|>assistant<|im_sep|>','')\n",
    "    print('replace',generated_text)\n",
    "    if generated_text.find('<|im_end|>')>=0:\n",
    "        generated_text = generated_text.split('<|im_end|>')[0]\n",
    "        print('spilt',generated_text)\n",
    "    elif generated_text.find('<|im_sep|>')>=0:\n",
    "        generated_text = generated_text.split('<|im_sep|>')[0]\n",
    "        print('split',generated_text)\n",
    "    elif generated_text.find('<|im_start|>')>=0:\n",
    "        generated_text = generated_text.split('<|im_start|>')[0]\n",
    "        print('slipt',generated_text)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if('device' not in globals()):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained('./Model/Fineturning')\n",
    "        model = GPT2LMHeadModel.from_pretrained('./Model/Fineturning')\n",
    "        model.to(device)\n",
    "\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone()\n",
    "    conversation = []\n",
    "    conversation.append({\n",
    "        'type':'assistant',\n",
    "        'message':'Chào bạn tôi có thể giúp gì cho bạn.'\n",
    "    })\n",
    "    print('=====================start===========')\n",
    "    while(True):\n",
    "        with mic as source:\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "            audio = recognizer.listen(source,timeout=None, phrase_time_limit=5)\n",
    "        try:\n",
    "            # Chuyển âm thanh thành văn bản (hỗ trợ tiếng Việt)\n",
    "            print('======================recording===========================')\n",
    "            text = recognizer.recognize_google(audio, language='vi-VN')\n",
    "            if(text.lower().find('stop')>=0): break\n",
    "            print(\"Bạn vừa nói:\", text)\n",
    "            conversation.append({\n",
    "                'type': 'user',\n",
    "                'message': text,\n",
    "            })\n",
    "            response = assistant(conversation)\n",
    "            conversation.append({\n",
    "                'type':'assistant',\n",
    "                'message':f'{response}<|im_end|>'\n",
    "            })\n",
    "            print(response)\n",
    "            text2speech(response);\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Không nhận dạng được giọng nói.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Lỗi kết nối: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['origin <|im_start|> assistant ',\n",
       " ' <|im_start|> assistant ',\n",
       " ' Chào bạn tôi có thể giúp gì cho bạn. <|im_end|> <|im_end|> <|im_start|> user ',\n",
       " ' Tôi buồn quá bạn ơi? <|im_end|> <|im_start|> assistant ',\n",
       " ' Có thể cho tôi một số lời khuyên để giảm bớt căng thẳng trong cuộc sống không? ',\n",
       " '  Trung, ấm áp, hiền lành, thật thà, chịu khó làm việc nhà và chăm sóc gia đình. công việc ổn định, không ràng buộc, có khả năng giao tiếp tốt, biết lắng nghe và chia sẻ cảm xúc với người khác. muốn tìm bạn tâm giao, vui tính, hòa đồng, quan trọng là biết quan tâm đến nhau, tôn trọng ý kiến của nhau.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = 'origin <|im_start|> assistant <|im_sep|> <|im_start|> assistant <|im_sep|> Chào bạn tôi có thể giúp gì cho bạn. <|im_end|> <|im_end|> <|im_start|> user <|im_sep|> Tôi buồn quá bạn ơi? <|im_end|> <|im_start|> assistant <|im_sep|> Có thể cho tôi một số lời khuyên để giảm bớt căng thẳng trong cuộc sống không? <|im_sep|>  Trung, ấm áp, hiền lành, thật thà, chịu khó làm việc nhà và chăm sóc gia đình. công việc ổn định, không ràng buộc, có khả năng giao tiếp tốt, biết lắng nghe và chia sẻ cảm xúc với người khác. muốn tìm bạn tâm giao, vui tính, hòa đồng, quan trọng là biết quan tâm đến nhau, tôn trọng ý kiến của nhau.'\n",
    "# a.split('<|im_sep|>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
